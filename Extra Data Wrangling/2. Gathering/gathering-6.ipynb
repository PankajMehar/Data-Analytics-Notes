{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mashup: APIs, Downloading Files Programmatically, and JSON\n",
    "\n",
    "With APIs, downloading files programmatically from the internet, and JSON under your belt, you now have all of the knowledge to download all of the movie poster images for the Roger Ebert review word clouds. This is your next task.\n",
    "\n",
    "There are two key things to be aware of before you begin:\n",
    "\n",
    "1. Wikipedia Page Titles\n",
    "To access Wikipedia page data via the MediaWiki API with wptools (phew, that was a mouthful), you need each movie's Wikipedia page title, i.e., what comes after the last slash in en.wikipedia.org/wiki/ in the URL. For this lesson, I've compiled all of these titles for each of the movies in the Top 100 for you.\n",
    "\n",
    "2. Downloading Image Files\n",
    "Downloading images may seem tricky from a reading and writing perspective, in comparison to text files which you can read line by line, for example. But in reality, image files aren't specialâ€”they're just binary files. To interact with them, you don't need special software (like Photoshop or something) that \"understands\" images. You can use regular file opening, reading, and writing techniques, like this:\n",
    "\n",
    "```\n",
    "import requests\n",
    "r = requests.get(url)\n",
    "with open(folder_name + '/' + filename, 'wb') as f:\n",
    "        f.write(r.content)\n",
    "```\n",
    "\n",
    "But this technique can be error-prone. It will work most of the time, but sometimes the file you write to will be damaged. \n",
    "\n",
    "This type of error is why the _requests library_ maintainers [recommend](http://docs.python-requests.org/en/latest/user/quickstart/#binary-response-content) using the [PIL library](https://pillow.readthedocs.io/) (short for Pillow) and __BytesIO__ from the io library for non-text requests, like images. They recommend that you access the response body as bytes, for non-text requests. \n",
    "\n",
    "For example, to create an image from binary data returned by a request:\n",
    "\n",
    "```\n",
    "import requests\n",
    "from PIL import Image\n",
    "from io import BytesIO\n",
    "r = requests.get(url)\n",
    "i = Image.open(BytesIO(r.content))\n",
    "```\n",
    "\n",
    "Though you may still encounter a similar file error, this code above will at least warn us with an error message, at which point we can manually download the problematic images."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Quiz\n",
    "Let's gather the last piece of data for the Roger Ebert review word clouds now: the movie poster image files. Let's also keep each image's URL to add to the master DataFrame later.\n",
    "\n",
    "Though we're going to use a loop to minimize repetition, here's how the major parts inside that loop will work, in order:\n",
    "\n",
    "1. We're going to query the MediaWiki API using wptools to get a movie poster URL via each page object's __image__ attribute.\n",
    "2. Using that URL, we'll programmatically download that image into a folder called _bestofrt_posters_."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Jupyter Notebook below contains template code that:\n",
    "\n",
    "- Contains title_list, which is a list of all of the Wikipedia page titles for each movie in the Rotten Tomatoes Top 100 Movies of All Time list. This list is in the same order as the Top 100.\n",
    "- Creates an empty list, df_list, to which dictionaries will be appended. This list of dictionaries will eventually be converted to a pandas DataFrame (this is the most efficient way of building a DataFrame row by row).\n",
    "- Creates an empty folder, bestofrt_posters, to store the downloaded movie poster image files.\n",
    "- Creates an empty dictionary, image_errors, to fill to keep track of movie poster image URLs that don't work.\n",
    "- Loops through the Wikipedia page titles in title_list and:\n",
    "    - Stores the ranking of that movie in the Top 100 list based on its position in title_list. Ranking is needed so we can join this DataFrame with the master DataFrame later. We can't join on title because the titles of the Rotten Tomatoes pages and the Wikipedia pages differ.\n",
    "    - Uses `try` and `except` blocks to attempt to query MediaWiki for a movie poster image URL and to attempt to download that image. If the attempt fails and an error is encountered, the offending movie is documented in image_errors.\n",
    "    - Appends a dictionary with ranking, title, and poster_url as the keys and the extracted values for each as the values to df_list.\n",
    "- Inspects the images that caused errors and downloads the correct image individually (either via another URL in the image attribute's list or a URL from Google Images)\n",
    "- Creates a DataFrame called df by converting df_list using the pd.DataFrame constructor.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
